{"cells":[{"cell_type":"markdown","metadata":{"id":"MBl0za9OjyJu"},"source":["# Credits\n","\n","This is heavily based on https://github.com/pytorch/tutorials"]},{"cell_type":"markdown","metadata":{"id":"U9PXH5CQjyJw"},"source":["# What is PyTorch?\n","\n","> **NOTE** In the last part of this lab cuda is used. If you have a cuda enabled machine, read the README.md in the root of this repo on how to use nvidia-docker.\n","\n","\n","It’s a Python based scientific computing package targeted at two sets of\n","audiences:\n","-  A replacement for numpy to use the power of GPUs\n","-  a deep learning research platform that provides maximum flexibility\n","   and speed\n"]},{"cell_type":"markdown","metadata":{"id":"1cKxmRJ4jyJw"},"source":["# Getting Started\n","\n","In this lab you will get a quick start on what pytorch is and how to use it.\n","\n","## 1. Tensors\n","\n","Tensors are similar to numpy’s ndarrays, with the addition being that\n","Tensors can also be used on a GPU to accelerate computing."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LiBzo-CjjyJx","executionInfo":{"status":"ok","timestamp":1726488768697,"user_tz":-120,"elapsed":3465,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}}},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{"id":"T2wRXl1zjyJy"},"source":["Construct a 5x3 matrix, uninitialized"]},{"cell_type":"code","execution_count":3,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"2BnpkezfjyJy","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":37,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"ac23c587-0031-4bed-94b6-d212052e5cf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[7.8868e-37, 3.1028e-41, 1.4013e-45],\n","        [0.0000e+00, 7.8865e-37, 3.1028e-41],\n","        [7.8865e-37, 3.1028e-41, 3.3631e-44],\n","        [1.0653e-38, 6.1616e-36, 4.3439e-41],\n","        [2.8026e-45, 4.1877e-38, 0.0000e+00]])\n"]}],"source":["x = torch.Tensor(5, 3)\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"ClJx4yp_jyJy"},"source":["Construct a randomly initialized matrix"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2M5qDaXjyJz","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":36,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"ccb21bfc-ecf8-4ff9-bc3e-c7cacda30142"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4193, 0.6919, 0.2049],\n","        [0.1541, 0.6849, 0.1672],\n","        [0.2279, 0.9655, 0.1359],\n","        [0.1461, 0.4890, 0.6315],\n","        [0.2238, 0.6095, 0.8083]])\n"]}],"source":["x = torch.rand(5, 3)\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"u3YlrmtZjyJ0"},"source":["Get its size"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNuAewncjyJ0","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":34,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"f6acd5f6-9bfe-4d2d-e60b-0aa0a65a65b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 3])\n"]}],"source":["print(x.size())"]},{"cell_type":"markdown","metadata":{"id":"VA99nIRyjyJ1"},"source":["**NOTE**: `torch.Size` is in fact a tuple, so it supports the same operations that a tuple supports."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeXx7lzKjyJ2","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":31,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"a346f968-d6a1-410c-f8a3-3247336ef3af"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4193, 0.6919, 0.2049],\n","        [2.0000, 2.0000, 2.0000],\n","        [2.0000, 2.0000, 2.0000],\n","        [0.1461, 0.4890, 0.6315],\n","        [0.2238, 0.6095, 0.8083]])\n"]}],"source":["x[1:3] = 2\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"v5p9mmVBjyJ2"},"source":["# Assignment\n","\n","Make use of the pytorch docs <http://pytorch.org/docs/torch>\n","1. Make a tensor of size (2, 17)\n","2. Make a torch.FloatTensor of size (3, 1)\n","3. Make a torch.LongTensor of size (5, 2, 1)\n","  - fill the entire tensor with 7s\n","4. Make a torch.ByteTensor of size (5,)\n","  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]"]},{"cell_type":"code","source":["print(torch.Tensor(2, 17).size())\n","print(torch.FloatTensor(3, 1).size())\n","float_tensor = torch.LongTensor(5, 2, 1)\n","print(float_tensor.size())\n","#float_tensor.fill_(7)\n","float_tensor[::] = 7\n","print(float_tensor)\n","byte_tensor = torch.ByteTensor(5,)\n","byte_tensor[1:4] = 3\n","print(byte_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GtS29aoleZC","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":30,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"bdc5b076-55d4-4526-bfa7-5acef76c5a6b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 17])\n","torch.Size([3, 1])\n","torch.Size([5, 2, 1])\n","tensor([[[7],\n","         [7]],\n","\n","        [[7],\n","         [7]],\n","\n","        [[7],\n","         [7]],\n","\n","        [[7],\n","         [7]],\n","\n","        [[7],\n","         [7]]])\n","tensor([96,  3,  3,  3, 23], dtype=torch.uint8)\n"]}]},{"cell_type":"markdown","metadata":{"id":"1rho08R9jyJ3"},"source":["## 2. Operations\n","There are multiple syntaxes for operations. Let's see addition as an example:\n","\n","### 2.1 Addition: syntax 1"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErXrh34CjyJ3","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":25,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"0d8fe5d8-e828-4e7b-9155-77557e7c5b67"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4561, 0.9270, 0.7070],\n","        [2.1613, 2.3072, 2.9042],\n","        [2.7646, 2.1279, 2.9896],\n","        [0.2061, 1.0954, 1.1738],\n","        [0.3730, 0.7660, 1.5888]])\n"]}],"source":["y = torch.rand(5, 3)\n","print(x + y)"]},{"cell_type":"markdown","metadata":{"id":"_p471aShjyJ3"},"source":["### 2.2 Addition: syntax 2"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyBxYSsGjyJ4","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":21,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"63fc09ec-73c0-4459-a227-b9438c5e7626"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4561, 0.9270, 0.7070],\n","        [2.1613, 2.3072, 2.9042],\n","        [2.7646, 2.1279, 2.9896],\n","        [0.2061, 1.0954, 1.1738],\n","        [0.3730, 0.7660, 1.5888]])\n"]}],"source":["print(torch.add(x, y))"]},{"cell_type":"markdown","metadata":{"id":"8u9zEGwRjyJ4"},"source":["### 2.3 Addition: giving an output tensor"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5hCPJBVjyJ4","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":19,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"e5c71f04-2ee3-49a7-fb5f-c38803bba2ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4561, 0.9270, 0.7070],\n","        [2.1613, 2.3072, 2.9042],\n","        [2.7646, 2.1279, 2.9896],\n","        [0.2061, 1.0954, 1.1738],\n","        [0.3730, 0.7660, 1.5888]])\n"]}],"source":["result = torch.Tensor(5, 3)\n","torch.add(x, y, out=result)\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"jUkRFLtljyJ5"},"source":["### 2.4 Addition: in-place\n","\n","adds `x`to `y`"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aC62y_X5jyJ5","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":18,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"3e55a8c2-e86d-48d6-9331-061f620a8b76"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4561, 0.9270, 0.7070],\n","        [2.1613, 2.3072, 2.9042],\n","        [2.7646, 2.1279, 2.9896],\n","        [0.2061, 1.0954, 1.1738],\n","        [0.3730, 0.7660, 1.5888]])\n"]}],"source":["y.add_(x)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"GnRqpRqyjyJ6"},"source":["**NOTE**: Any operation that mutates a tensor in-place is post-fixed with an `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`."]},{"cell_type":"markdown","metadata":{"id":"gyeNzwMXjyJ6"},"source":["You can use standard numpy-like indexing with all bells and whistles!"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkngfMC6jyJ6","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":16,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"ab687997-4836-410f-a1c2-185f6e26a103"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.6919, 2.0000, 2.0000, 0.4890, 0.6095])\n"]}],"source":["print(x[:, 1])"]},{"cell_type":"markdown","metadata":{"id":"T_J1YcnOjyJ7"},"source":["**Read later** 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described here <http://pytorch.org/docs/torch>"]},{"cell_type":"markdown","metadata":{"id":"sRMf4X2VjyJ7"},"source":["# Assignment\n","\n","1. multiplication of two tensors (see [torch.Tensor.mul](http://pytorch.org/docs/master/tensors.html#torch.Tensor.mul))\n","2. do the same, but inplace\n","3. division of two tensors (see [torch.Tensor.div](http://pytorch.org/docs/master/tensors.html#torch.Tensor.div))\n","4. perform a matrix multiplication of two tensors of size (2, 4) and (4, 2)"]},{"cell_type":"code","source":["print(torch.mul(x, y))\n","print(y.mul_(x))\n","print(torch.div(x, y))\n","print(torch.matmul(torch.Tensor(2,4), torch.Tensor(4,2)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cuaZpCrntlVp","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":15,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"d6fc39da-b333-47c1-dece-ff0a096d34c8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1912, 0.6414, 0.1448],\n","        [4.3226, 4.6144, 5.8084],\n","        [5.5292, 4.2559, 5.9791],\n","        [0.0301, 0.5357, 0.7413],\n","        [0.0835, 0.4669, 1.2843]])\n","tensor([[0.1912, 0.6414, 0.1448],\n","        [4.3226, 4.6144, 5.8084],\n","        [5.5292, 4.2559, 5.9791],\n","        [0.0301, 0.5357, 0.7413],\n","        [0.0835, 0.4669, 1.2843]])\n","tensor([[2.1927, 1.0787, 1.4143],\n","        [0.4627, 0.4334, 0.3443],\n","        [0.3617, 0.4699, 0.3345],\n","        [4.8511, 0.9129, 0.8519],\n","        [2.6813, 1.3054, 0.6294]])\n","tensor([[0., 0.],\n","        [0., 0.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"1yY684CKjyJ7"},"source":["## 3. Numpy Bridge\n","\n","Converting a torch Tensor to a numpy array and vice versa is a breeze.\n","\n","The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n","\n","### 3.1 Converting torch Tensor to numpy Array"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YZimawdjyJ8","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":12,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"ebba9b21-c316-4780-fcaa-19407ff8e43e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1.])\n"]}],"source":["a = torch.ones(5)\n","print(a)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQC0qGyCjyJ8","executionInfo":{"status":"ok","timestamp":1726488768698,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"474f2c72-0fbf-44b8-fdcf-39d51cf9597b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 1. 1. 1. 1.]\n"]}],"source":["b = a.numpy()\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"nwk5P7UHjyJ9"},"source":["See how the numpy array changed in value: the `numpy()` method provides a *view* of the original tensor, not a copy."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0QAxl7pjyJ9","executionInfo":{"status":"ok","timestamp":1726488768699,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"7a49a118-63aa-4c97-e09d-daa2b53fbf50"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"]}],"source":["a.add_(1)\n","print(a)\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"QhNUjOzXjyJ-"},"source":["### 3.2 Converting numpy Array to torch Tensor\n","\n","See how changing the np array changed the torch Tensor automatically"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1ciIEPfjyJ-","executionInfo":{"status":"ok","timestamp":1726488768699,"user_tz":-120,"elapsed":8,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"62817158-d92d-4103-9dc4-625e759d6889"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"]}],"source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a)\n","print(a)\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"FLwdkuG9jyJ_"},"source":["# Assignment\n","\n","1. create a tensor of size (5, 2) containing ones\n","2. now convert it to a numpy array\n","3. now convert it back to a torch tensor"]},{"cell_type":"code","source":["a = torch.ones(5,2)\n","b = a.numpy()\n","c = torch.from_numpy(b)\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbwOuFv0uvRJ","executionInfo":{"status":"ok","timestamp":1726488768699,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"04fcdbee-5947-491d-b66f-717086187343"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.],\n","        [1., 1.],\n","        [1., 1.],\n","        [1., 1.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"-W3rMaDYjyKB"},"source":["All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n","\n","## 4 CUDA Tensors\n","\n","Tensors can be moved onto GPU using the `.cuda` function.\n","This is not necessary, but check the `README.md` for details on how to use a GPU with docker."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngIe6G7LjyKC","executionInfo":{"status":"ok","timestamp":1726488769683,"user_tz":-120,"elapsed":989,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}},"outputId":"f863c733-d8ac-4351-89cc-09bcd7d6e2bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4193, 0.6919, 0.2049],\n","        [2.0000, 2.0000, 2.0000],\n","        [2.0000, 2.0000, 2.0000],\n","        [0.1461, 0.4890, 0.6315],\n","        [0.2238, 0.6095, 0.8083]], device='cuda:0')\n","tensor([[0.1912, 0.6414, 0.1448],\n","        [4.3226, 4.6144, 5.8084],\n","        [5.5292, 4.2559, 5.9791],\n","        [0.0301, 0.5357, 0.7413],\n","        [0.0835, 0.4669, 1.2843]], device='cuda:0')\n","tensor([[0.6106, 1.3332, 0.3497],\n","        [6.3226, 6.6144, 7.8084],\n","        [7.5292, 6.2559, 7.9791],\n","        [0.1762, 1.0247, 1.3728],\n","        [0.3073, 1.0764, 2.0926]], device='cuda:0')\n"]}],"source":["# let us run this cell only if CUDA is available\n","if torch.cuda.is_available():\n","    x = x.cuda()\n","    y = y.cuda()\n","    z = x + y\n","    # Notice that the tensors are now of type torch.cuda.FloatTensor (notice the cuda in there)\n","    # This is meant as a tensor to be run on the GPU.\n","    # The .cuda() does this to any parameter it is applied to.\n","    print(x)\n","    print(y)\n","    print(z)\n","else:\n","    print(\"CUDA not available on your machine.\")"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"U512JH7SjyKC","executionInfo":{"status":"ok","timestamp":1726488769683,"user_tz":-120,"elapsed":3,"user":{"displayName":"Mathias Damsgaard","userId":"03024566121046196023"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}